{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa94a4-6590-4aa2-b04e-c2fbb68556c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import WhisperSegmenter, WhisperSegmenterFast\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from train import validate\n",
    "from datautils import get_audio_and_label_paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7600a8-a69a-4dad-9761-17bf48236ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmenter = WhisperSegmenter(  model_path = \"nccratliri/whisperseg-zebra-finch\", \n",
    "                        device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c2be6-1855-4171-8ace-9e15b9c27fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname_list = sorted( [fname for fname in os.listdir(\"data/dataset/zebseg/\") if fname != \"all_birds\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54bb88-abc8-44a0-8c7a-d881ef15d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in fname_list:\n",
    "    audio_paths, label_paths = get_audio_and_label_paths(\"data/dataset/zebseg/%s/test/\"%(fname))\n",
    "\n",
    "    audio_list, label_list = [], []\n",
    "    for audio_path, label_path in zip(audio_paths, label_paths):\n",
    "        audio, _ = librosa.load( audio_path, sr = 16000 )\n",
    "        label_df = pd.read_csv( label_path )\n",
    "        label = {\n",
    "            \"onset\":list(label_df[\"onset\"]),\n",
    "            \"offset\":list(label_df[\"offset\"]),\n",
    "            \"cluster\":list(label_df[\"cluster\"]) \n",
    "        }\n",
    "        audio_list.append(audio)\n",
    "        label_list.append(label)\n",
    "    \n",
    "    \n",
    "    res = validate( audio_list, label_list, segmenter, sr = 16000, tolerance = 0.02, num_trials = 3 , min_segment_length = 0.02,\n",
    "              voting_time_step = 1.0, voting_precision = 0.001, batch_size = 8, max_length = 400, eps = 0.02, target_cluster = None )\n",
    "    print(fname+\":\\t\", res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ac3a8-23e7-40e7-8414-b0c8d0e2480d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syllable_segment]",
   "language": "python",
   "name": "conda-env-syllable_segment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
