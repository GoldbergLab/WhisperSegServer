{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c427f5b3-889f-4ffe-84f7-5f43bc264a0b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ffdfb7-9d76-4a60-a358-d706bc599b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb7f85f-0752-4638-9aa6-17c079ce2fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import WhisperSegmenterFast, WhisperSegmenter\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from train import evaluate\n",
    "from datautils import get_audio_and_label_paths\n",
    "import os\n",
    "from audio_utils import SpecViewer\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fdd2c5-b6cd-4b50-94cf-237120c00006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_dataset( dataset_folder, model_path, num_trials, consolidation_method = \"clustering\",\n",
    "                      max_length = 448, num_beams = 4, batch_size = 8, tolerance = None, spec_time_step = None, eps = None ):\n",
    "    audio_list, label_list = [], []\n",
    "    audio_paths, label_paths = get_audio_and_label_paths(dataset_folder)\n",
    "    for audio_path, label_path in zip(audio_paths, label_paths):\n",
    "        label = json.load( open( label_path ) )\n",
    "        audio, _ = librosa.load( audio_path, sr = label[\"sr\"] )\n",
    "        audio_list.append(audio)\n",
    "        label_list.append(label) \n",
    "        \n",
    "        if tolerance is not None:\n",
    "            label[\"tolerance\"] = tolerance\n",
    "        if spec_time_step is not None:\n",
    "            label[\"spec_time_step\"] = spec_time_step\n",
    "        if eps is not None:\n",
    "            label[\"eps\"] = eps \n",
    "\n",
    "\n",
    "    segmenter = WhisperSegmenterFast(  model_path = model_path,  device = \"cuda\")\n",
    "    res = evaluate( audio_list, label_list, segmenter, batch_size, max_length, num_trials, consolidation_method, num_beams, \n",
    "                    target_cluster = None\n",
    "                  )\n",
    "\n",
    "    all_res = {\n",
    "        \"segment_wise_scores\": {\"N-true-positive\": res[\"segment_wise\"][0],\n",
    "                                \"N-positive-in-prediction\": res[\"segment_wise\"][1],\n",
    "                                \"N-positive-in-ground-truth\": res[\"segment_wise\"][2],\n",
    "                                \"precision\": res[\"segment_wise\"][3],\n",
    "                                \"recall\": res[\"segment_wise\"][4],\n",
    "                                \"F1\": res[\"segment_wise\"][5]\n",
    "                                },\n",
    "        \"frame_wise_scores\": {\"N-true-positive\": res[\"frame_wise\"][0],\n",
    "                                \"N-positive-in-prediction\": res[\"frame_wise\"][1],\n",
    "                                \"N-positive-in-ground-truth\": res[\"frame_wise\"][2],\n",
    "                                \"precision\": res[\"frame_wise\"][3],\n",
    "                                \"recall\": res[\"frame_wise\"][4],\n",
    "                                \"F1\": res[\"frame_wise\"][5]\n",
    "                                }\n",
    "    }\n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3994325c-0a3e-4220-93b9-567c6c238ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283b3466095f42bba375978f73a01fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16230f7b7cfe45249cc338679895aa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58d833163264abcaf8823844a03b38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/special_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513d36ee81d04ee09bbdcc73a48f9a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9659ece5c2bc46fe971a2266b84d6a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/added_tokens.json:   0%|          | 0.00/22.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6dbe917fbb479e806a0c227e651093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce55ec6d24e84f78b001625cf9222089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/config.json:   0%|          | 0.00/2.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7faf7c58ac403ea5bb89cf41b06ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc6cdcf88c546cb89164959c15c2597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bd4553042445cf8963ab116a6561b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3fba42adda4cfebd61453573a7cef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ae7ca73cb94294b30c2056d811dd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56ef8e4a028462cae76425d466966be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:18<00:00,  3.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 207,\n",
       "  'N-positive-in-prediction': 256,\n",
       "  'N-positive-in-ground-truth': 274,\n",
       "  'precision': 0.80859375,\n",
       "  'recall': 0.7554744525547445,\n",
       "  'F1': 0.7811320754716982},\n",
       " 'frame_wise_scores': {'N-true-positive': 40393,\n",
       "  'N-positive-in-prediction': 42145,\n",
       "  'N-positive-in-ground-truth': 46324,\n",
       "  'precision': 0.9584292324119112,\n",
       "  'recall': 0.8719670149382609,\n",
       "  'F1': 0.9131560207530321}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/datasets/meerkat/data/test/\", \n",
    "                 \"nccratliri/whisperseg-meerkat-vad-ct2\", \n",
    "                  num_trials = 3, tolerance = 0.02 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea393024-fe24-433c-931f-045c8a8953f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79060c458a6447cba32a62a4c459d873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaeeeee28ea94b91a333db2ac7abbbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segment_wise_scores': {'N-true-positive': 207,\n",
       "  'N-positive-in-prediction': 255,\n",
       "  'N-positive-in-ground-truth': 274,\n",
       "  'precision': 0.8117647058823529,\n",
       "  'recall': 0.7554744525547445,\n",
       "  'F1': 0.782608695652174},\n",
       " 'frame_wise_scores': {'N-true-positive': 40264,\n",
       "  'N-positive-in-prediction': 42009,\n",
       "  'N-positive-in-ground-truth': 46324,\n",
       "  'precision': 0.9584612821062153,\n",
       "  'recall': 0.8691822813228564,\n",
       "  'F1': 0.9116411760044377}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset( \"../data/example_subset/Meerkat/test/\", \n",
    "                 \"nccratliri/whisperseg-meerkat-vad-ct2\", \n",
    "                  num_trials = 3, tolerance = 0.02 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47354645-dd38-45ce-b2b7-a8262e4fcc78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests,json,base64\n",
    "\n",
    "## define a function for segmentation\n",
    "def call_segment_service( service_address, \n",
    "                          audio_file_path,\n",
    "                          channel_id,\n",
    "                          sr,\n",
    "                          min_frequency,\n",
    "                          spec_time_step,\n",
    "                          min_segment_length,\n",
    "                          eps,\n",
    "                          num_trials\n",
    "                        ):\n",
    "    audio_file_base64_string = base64.b64encode( open(audio_file_path, 'rb').read()).decode('ASCII')\n",
    "    response = requests.post( service_address,\n",
    "                              data = json.dumps( {\n",
    "                                  \"audio_file_base64_string\":audio_file_base64_string,\n",
    "                                  \"channel_id\":channel_id,\n",
    "                                  \"sr\":sr,\n",
    "                                  \"min_frequency\":min_frequency,\n",
    "                                  \"spec_time_step\":spec_time_step,\n",
    "                                  \"min_segment_length\":min_segment_length,\n",
    "                                  \"eps\":eps,\n",
    "                                  \"num_trials\":num_trials\n",
    "                              } ),\n",
    "                              headers = {\"Content-Type\": \"application/json\"}\n",
    "                            )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719bb28a-228b-4543-ad2c-a49d472bcf0c",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a11e645-9abe-4664-ab1a-562f4583af55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from model import WhisperSegmenterFast, WhisperSegmenter\n",
    "from audio_utils import SpecViewer\n",
    "segmenter = WhisperSegmenterFast( \"nccratliri/whisperseg-meerkat-vad-ct2\", device=\"cuda\" )\n",
    "# segmenter = WhisperSegmenter( \"nccratliri/whisperseg-large-vad-v1.0\", device=\"cuda\" )\n",
    "spec_viewer = SpecViewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f120142-10a3-4c8c-94c8-3c4af051df29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_file = \"../data/example_subset/Meerkat/test/VLM298_L_4_27DEC2022_MF_ML.wav\"\n",
    "label_file = audio_file[:-4] + \".json\"\n",
    "data = json.load(open(label_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df54b61-5486-4f87-96de-a0c7d67d7dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345b24a830214be2aec2ee0370d20a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=13.5, description='offset', max=27.0345625, step=0.25), Output()), _do…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = data[\"sr\"]  \n",
    "min_frequency = data[\"min_frequency\"]\n",
    "spec_time_step = data[\"spec_time_step\"]\n",
    "min_segment_length = data[\"min_segment_length\"]\n",
    "eps = data[\"eps\"]\n",
    "num_trials = 1\n",
    "\n",
    "audio, _ = librosa.load( audio_file, sr = sr )\n",
    "label = json.load( open(label_file) )\n",
    "\n",
    "prediction = segmenter.segment(  audio, sr = sr, min_frequency = min_frequency, spec_time_step = spec_time_step,\n",
    "                       min_segment_length = min_segment_length, eps = eps,num_trials = num_trials, batch_size=4 )\n",
    "spec_viewer.visualize( audio = audio, sr = sr, min_frequency= min_frequency, prediction = prediction, label=label, \n",
    "                       window_size=5, precision_bits=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92976494-803c-4a79-a7b6-b7a0dd433882",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0186e5128de4266b8044ea676cd9679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=13.5, description='offset', max=27.0345625, step=0.25), Output()), _do…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2 = call_segment_service( \"http://localhost:8050/segment\", \n",
    "                          audio_file,   \n",
    "                          channel_id = 0,\n",
    "                          sr = sr,\n",
    "                          min_frequency = min_frequency,\n",
    "                          spec_time_step = spec_time_step,\n",
    "                          min_segment_length = min_segment_length,\n",
    "                          eps = eps,\n",
    "                          num_trials = num_trials\n",
    "                        )\n",
    "spec_viewer.visualize( audio = audio, sr = sr, min_frequency= min_frequency, prediction = prediction2, label=label, \n",
    "                       window_size=5, precision_bits=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57a84275-d078-4a62-802c-903b6cbb3f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction == prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9ff90-b3a2-45fa-8a64-009813f2b455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wseg]",
   "language": "python",
   "name": "conda-env-wseg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
