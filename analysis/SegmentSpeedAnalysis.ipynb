{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dc0c17-e5c6-459d-88f0-dd1901152fd5",
   "metadata": {},
   "source": [
    "## Speed Comparison between WhisperSegmenterFast and faster-whisper (https://github.com/guillaumekln/faster-whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8173a5f-eb62-4a2c-8469-03e2dc6b60b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Performance on GPU\n",
    "\n",
    "Tested on NVIDIA A100 GPU 40 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8990a-9d3a-4a99-91f6-e5ab2740a54f",
   "metadata": {},
   "source": [
    "#### speed of faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf72dd4-c099-4714-b44d-f1740094c6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2006655db3724483b1c8a681cb602b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## This code comes from the github repo of faster-whisper: \n",
    "## https://github.com/guillaumekln/faster-whisper#transcription\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "model_size = \"large-v2\"\n",
    "faster_whisper_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64ddb56-f16e-493f-a3fd-24b9c1c4fcc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating duration from bitrate, this may be inaccurate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of audio: 13.32 min\n",
      "Segmentation time: 56.542324 s for segmenting 13.32 minutes audio\n"
     ]
    }
   ],
   "source": [
    "audio_name = \"data/speed_test/test_audio.mp3\"\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "total_audio_length = len(audio)/16000\n",
    "print(\"Total length of audio: %.2f min\"%(total_audio_length/60))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "segments, info  = faster_whisper_model.transcribe(audio_name, beam_size=5)\n",
    "\"\"\"\n",
    "    If you comment out the following two lines, you will witness a 8x speedup. \n",
    "    However, this speed is not useful, beacause the segments above is a generator. To get the real content from it,\n",
    "    one must loop through the generator, and this loop turns out to be slow, but necessary. \n",
    "    Therefore, the following two lines should be counted into the time spent by faster-whisper\n",
    "\"\"\"\n",
    "res = []\n",
    "for segment in segments:\n",
    "    res.append((segment.start, segment.end, segment.text))\n",
    "    \n",
    "tac = time.time()\n",
    "print(\"Segmentation time: %f s for segmenting %.2f minutes audio\"%(tac - tic, total_audio_length/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba682b96-5c26-4962-8808-50aa3693d964",
   "metadata": {
    "tags": []
   },
   "source": [
    "The file data/speed_test/test_audio.mp3 is the same file used in the benchmark in https://github.com/guillaumekln/faster-whisper#benchmark, where the authors reported that it took **54 s** to segment this 13 min audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93675570-27f6-483a-9346-92a479390fcc",
   "metadata": {},
   "source": [
    "#### Speed of WhisperSegmenterFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f153c90-b4d9-428f-b873-b72ace47afa0",
   "metadata": {},
   "source": [
    "For a fair comparison, we let WhisperSegmenterFast segment bird song audio that is also 13 min long. \n",
    "\n",
    "This 13-min birdsong audio is created by merging multiple birdsong audio files.\n",
    "\n",
    "We do not let WhisperSegmenterFast segment data/speed_test/test_audio.mp3 because this .mp3 file contains human talk. In this case WhisperSegmenterFast will extract no birdsong syllables from it, and the segmentation will be very fast and we might overestimate the speed of WhisperSegmenterFast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a06cf03-c5ae-40d6-872b-d40db45f125f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import WhisperSegmenterFast\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6019ec2b-d44a-4166-93f4-8bb936c18d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmenter_fast = WhisperSegmenterFast( \"model/vocal-segment-zebra-finch-whisper-large-ct2\", device=\"cuda\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac9c3c60-c0b6-43f8-897f-bb1a9ecf7194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of audio: 13.32 min\n",
      "Segmentation time: 39.355548 s for segmenting 13.32 minutes audio\n"
     ]
    }
   ],
   "source": [
    "audio_name = \"data/speed_test/test_birdsong_audio.wav\"\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "total_audio_length = len(audio)/16000\n",
    "print(\"Total length of audio: %.2f min\"%(total_audio_length/60))\n",
    "\n",
    "tic = time.time()\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "prediction = segmenter_fast.segment(audio, num_trials= 3)\n",
    "tac = time.time()\n",
    "print(\"Segmentation time: %f s for segmenting %.2f minutes audio\"%(tac - tic, total_audio_length/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cbd58-0438-4584-be79-873355a81f0c",
   "metadata": {},
   "source": [
    "The segmentation looks reasonable, as shown by visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d81e25e-7f16-4d8a-83e2-15c47fcca6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50b59b39ba14bfe9fa82cfe787905f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=397.1, description='offset', max=794.2), Output()), _dom_classes=('widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmenter_fast.visualize(audio = audio, prediction=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8bafb7-8e22-4f0d-92ef-22f73a80c2a4",
   "metadata": {},
   "source": [
    "**Conclusion: The speed between both WhisperSegmenterFast and faster-whipser is comparable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8150b-df4d-4980-8af9-03830398da21",
   "metadata": {},
   "source": [
    "### Performance on CPU\n",
    "\n",
    "Tested on AMD EPYC 7H12 64-Core Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bcb83-159c-4ea5-b6c4-cf9e2b4b263b",
   "metadata": {},
   "source": [
    "#### speed of faster-whisper -- the small whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795fd79a-5595-4013-8b3c-43b305cf2332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb720c86844413fbfb2d025fc45200c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating duration from bitrate, this may be inaccurate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of audio: 13.32 min\n",
      "Segmentation time: 2.84 min for segmenting 13.32 minutes audio\n"
     ]
    }
   ],
   "source": [
    "## This code comes from the github repo of faster-whisper: \n",
    "## https://github.com/guillaumekln/faster-whisper#transcription\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "model_size = \"small\"\n",
    "faster_whisper_model = WhisperModel(model_size, device=\"cpu\", compute_type=\"float32\")\n",
    "\n",
    "audio_name = \"data/speed_test/test_audio.mp3\"\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "total_audio_length = len(audio)/16000\n",
    "print(\"Total length of audio: %.2f min\"%(total_audio_length/60))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "segments, info  = faster_whisper_model.transcribe(audio_name, beam_size=5)\n",
    "\"\"\"\n",
    "    If you comment out the following two lines, you will witness a 8x speedup. \n",
    "    However, this speed is not useful, beacause the segments above is a generator. To get the real content from it,\n",
    "    one must loop through the generator, and this loop turns out to be slow, but necessary. \n",
    "    Therefore, the following two lines should be counted into the time spent by faster-whisper\n",
    "\"\"\"\n",
    "res = []\n",
    "for segment in segments:\n",
    "    res.append((segment.start, segment.end, segment.text))\n",
    "    \n",
    "tac = time.time()\n",
    "print(\"Segmentation time: %.2f min for segmenting %.2f minutes audio\"%((tac - tic)/60, total_audio_length/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c1b2b-2a32-4c8c-9cc1-738a778304a0",
   "metadata": {},
   "source": [
    "In the benchmark in https://github.com/guillaumekln/faster-whisper#benchmark, where the authors reported that it took **2 min 44 s** to segment this 13 min audio with **small whisper on CPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b3d22-74be-42d5-8d18-7a62d2bff09b",
   "metadata": {},
   "source": [
    "#### speed of faster-whisper -- the large whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e80ac8e-e163-4f10-9e18-2feb93c95a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b84c9ec8e543d99647390d4a9bdfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating duration from bitrate, this may be inaccurate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of audio: 13.32 min\n",
      "Segmentation time: 14.41 min for segmenting 13.32 minutes audio\n"
     ]
    }
   ],
   "source": [
    "## This code comes from the github repo of faster-whisper: \n",
    "## https://github.com/guillaumekln/faster-whisper#transcription\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "model_size = \"large-v2\"\n",
    "faster_whisper_model = WhisperModel(model_size, device=\"cpu\", compute_type=\"float32\")\n",
    "\n",
    "audio_name = \"data/speed_test/test_audio.mp3\"\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "total_audio_length = len(audio)/16000\n",
    "print(\"Total length of audio: %.2f min\"%(total_audio_length/60))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "segments, info  = faster_whisper_model.transcribe(audio_name, beam_size=5)\n",
    "\"\"\"\n",
    "    If you comment out the following two lines, you will witness a 8x speedup. \n",
    "    However, this speed is not useful, beacause the segments above is a generator. To get the real content from it,\n",
    "    one must loop through the generator, and this loop turns out to be slow, but necessary. \n",
    "    Therefore, the following two lines should be counted into the time spent by faster-whisper\n",
    "\"\"\"\n",
    "res = []\n",
    "for segment in segments:\n",
    "    res.append((segment.start, segment.end, segment.text))\n",
    "    \n",
    "tac = time.time()\n",
    "print(\"Segmentation time: %.2f min for segmenting %.2f minutes audio\"%((tac - tic)/60, total_audio_length/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eeaa60-afd8-4b47-84bf-7a518d945811",
   "metadata": {},
   "source": [
    "#### speed of WhisperSegmenterFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a04c773-a63d-4134-aae5-475ba0de9436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of audio: 13.32 min\n",
      "Segmentation time: 580.828187 s for segmenting 13.32 minutes audio\n"
     ]
    }
   ],
   "source": [
    "from model import WhisperSegmenterFast\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "segmenter_fast = WhisperSegmenterFast( \"model/vocal-segment-zebra-finch-whisper-large-ct2\", device=\"cpu\", compute_type=\"float32\" )\n",
    "\n",
    "audio_name = \"data/speed_test/test_birdsong_audio.wav\"\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "total_audio_length = len(audio)/16000\n",
    "print(\"Total length of audio: %.2f min\"%(total_audio_length/60))\n",
    "\n",
    "tic = time.time()\n",
    "audio, _ = librosa.load(audio_name, sr = 16000)\n",
    "prediction = segmenter_fast.segment(audio, num_trials= 1)\n",
    "tac = time.time()\n",
    "print(\"Segmentation time: %f s for segmenting %.2f minutes audio\"%(tac - tic, total_audio_length/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbc282-be83-49b4-b462-ac2914a3404c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f775b8bb-d30e-499a-b094-8da60b51d7e2",
   "metadata": {},
   "source": [
    "## GPU Usage of WhisperSegmenterFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed4b27-c1f2-4d91-b0d6-2ddafdce5eba",
   "metadata": {},
   "source": [
    "GPU usage when idle: 3.8 GB <br>\n",
    "GPU usage when segmenting (with a internal batch size 16):  up to 6 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e3de4-4c3f-4d57-986b-b6583cd58ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
