{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aaf7fb-ebaf-44e9-92e9-810d302bffcd",
   "metadata": {},
   "source": [
    "Note: This is a script for preparing the dataset. Runnning this script requires a animal call database.\n",
    "Therefore, this script is only for internal debugging purpose. You can create the training / test dataset using your own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d51632d-c982-42dc-9923-4683a75bbf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()) )\n",
    "from database_manager import WavDB\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adac36f2-dceb-4007-a1e6-6aa2c86aacc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_path = \"../../data/database/DB.splite\"\n",
    "archive_folder = \"../../data/database/archive/\"\n",
    "wav_db = WavDB( db_path = db_path, archive_folder = archive_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9b1518-83b0-437b-9836-f88147057863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122cffc-51e7-461d-b22b-bf5df538c147",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Zebseg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657dacf-3ad6-4c04-962e-58f5585c4005",
   "metadata": {},
   "source": [
    "## Separate bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4868c73-5375-4843-b2c0-f0e900623db6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 320.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 314.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 338.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 177/177 [00:00<00:00, 265.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 335.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 337.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 316.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 290.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 172.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 257/257 [00:00<00:00, 312.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 337.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 353.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 401.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 303.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 294.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 366.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 327.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 270.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 198.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 212.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 285.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 217.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 128.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 893/893 [00:01<00:00, 512.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<00:00, 516.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 746/746 [00:01<00:00, 431.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:00<00:00, 444.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 480.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 489.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 527.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 515.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for bird_and_age in [\"R3406_035\", \"R3406_045\", \"R3406_055\",\n",
    "                     \"R3428_039\", \"R3428_049\", \"R3428_059\",\n",
    "                     \"R3549_043\", \"R3549_053\", \"R3549_063\",\n",
    "                     \"R3625_045\", \"R3625_055\", \"R3625_065\",\n",
    "                     \"g17y2\", \"g4p5\", \"g19o10\", \"g19o3\"\n",
    "                    ]:\n",
    "    bird_name, bird_age = (bird_and_age.split(\"_\")+[\"\"])[:2]\n",
    "    \n",
    "    for mode in [\"train\", \"test\"]:\n",
    "    \n",
    "        dataset_folder = f\"data/dataset/zebseg/{bird_and_age}/{mode}\"\n",
    "        os.makedirs(dataset_folder)\n",
    "        audio_path_list, label_path_list = wav_db.get_audio_and_label_paths( \n",
    "             ( f\"collection=='zebseg' AND participant_name=='{bird_name}' AND participant_age=='{bird_age}' AND train_or_test=='{mode}'\", [] )  )    \n",
    "\n",
    "        for audio_path, csv_path in tqdm(zip(audio_path_list, label_path_list), total=len(audio_path_list)):\n",
    "            assert audio_path.endswith(\".wav\") and csv_path.endswith(\".csv\")\n",
    "            shutil.copy( audio_path, dataset_folder+\"/\" )\n",
    "            shutil.copy( csv_path, dataset_folder+\"/\" )\n",
    "            \n",
    "            csv_basename = os.path.basename( csv_path )\n",
    "            target_csv_path = dataset_folder + \"/\" + csv_basename\n",
    "            label_df = pd.read_csv( target_csv_path )\n",
    "            onset = np.array(label_df[\"onset\"])\n",
    "            duration = np.array(label_df[\"duration\"])\n",
    "            offset = onset + duration\n",
    "            cluster = np.array([0] * len(onset))\n",
    "            pd.DataFrame(\n",
    "                    {\"onset\":onset,\n",
    "                     \"offset\":offset,\n",
    "                     \"cluster\":cluster\n",
    "                    }\n",
    "            ).to_csv( target_csv_path, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0288df-5452-4d83-81fa-73b5597cd2c6",
   "metadata": {},
   "source": [
    "## All Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4808225-3a2f-4ecf-8e07-49f9e8df3885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2606/2606 [00:04<00:00, 603.26it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"data/dataset/zebseg/all_birds/train\"\n",
    "os.makedirs(dataset_folder)\n",
    "audio_path_list, label_path_list = wav_db.get_audio_and_label_paths( \n",
    "     ( \"collection=='zebseg' AND train_or_test=='train'\", [] )  )\n",
    "\n",
    "for audio_path, csv_path in tqdm(zip(audio_path_list, label_path_list), total=len(audio_path_list)):\n",
    "    assert audio_path.endswith(\".wav\") and csv_path.endswith(\".csv\")\n",
    "    shutil.copy( audio_path, dataset_folder+\"/\" )\n",
    "    shutil.copy( csv_path, dataset_folder+\"/\" )\n",
    "    \n",
    "    csv_basename = os.path.basename( csv_path )\n",
    "    target_csv_path = dataset_folder + \"/\" + csv_basename\n",
    "    label_df = pd.read_csv( target_csv_path )\n",
    "    onset = np.array(label_df[\"onset\"])\n",
    "    duration = np.array(label_df[\"duration\"])\n",
    "    offset = onset + duration\n",
    "    cluster = np.array([0] * len(onset))\n",
    "    pd.DataFrame(\n",
    "            {\"onset\":onset,\n",
    "             \"offset\":offset,\n",
    "             \"cluster\":cluster\n",
    "            }\n",
    "    ).to_csv( target_csv_path, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8202ae6a-b830-4c52-b9da-3e2701029ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 283/283 [00:00<00:00, 613.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"data/dataset/zebseg/all_birds/test\"\n",
    "os.makedirs(dataset_folder)\n",
    "audio_path_list, label_path_list = wav_db.get_audio_and_label_paths( \n",
    "     ( \"collection=='zebseg' AND train_or_test=='test'\", [] )  )\n",
    "\n",
    "for audio_path, csv_path in tqdm(zip(audio_path_list, label_path_list), total=len(audio_path_list)):\n",
    "    assert audio_path.endswith(\".wav\") and csv_path.endswith(\".csv\")\n",
    "    shutil.copy( audio_path, dataset_folder+\"/\" )\n",
    "    shutil.copy( csv_path, dataset_folder+\"/\" )\n",
    "    \n",
    "    csv_basename = os.path.basename( csv_path )\n",
    "    target_csv_path = dataset_folder + \"/\" + csv_basename\n",
    "    label_df = pd.read_csv( target_csv_path )\n",
    "    onset = np.array(label_df[\"onset\"])\n",
    "    duration = np.array(label_df[\"duration\"])\n",
    "    offset = onset + duration\n",
    "    cluster = np.array([0] * len(onset))\n",
    "    pd.DataFrame(\n",
    "            {\"onset\":onset,\n",
    "             \"offset\":offset,\n",
    "             \"cluster\":cluster\n",
    "            }\n",
    "    ).to_csv( target_csv_path, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522679d-b4a9-4951-bcf7-b08180cb0271",
   "metadata": {},
   "source": [
    "# Canary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c9dcb0-d5a6-4567-b47c-820b876a6ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/raw/Canary/O5P5U-f00035_November_15_2022_07_26_50.wav',\n",
       "  'data/raw/Canary/O5P5U-f00035_November_15_2022_07_26_50_Labels.txt'),\n",
       " ('data/raw/Canary/O5P5U-f00010_November_15_2022_07_15_19.wav',\n",
       "  'data/raw/Canary/O5P5U-f00010_November_15_2022_07_15_19_Labels.txt'),\n",
       " ('data/raw/Canary/O5P5U-f00019_November_15_2022_07_21_37.wav',\n",
       "  'data/raw/Canary/O5P5U-f00019_November_15_2022_07_21_37_Labels.txt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_anno_list = []\n",
    "raw_data_folder = \"data/raw/Canary/\"\n",
    "for fname in os.listdir(raw_data_folder):\n",
    "    if fname.endswith(\".wav\"):\n",
    "        wav_name = raw_data_folder+fname\n",
    "        anno_name = wav_name[:-4] + \"_Labels.txt\"\n",
    "        if os.path.exists(anno_name):\n",
    "            wav_anno_list.append((wav_name, anno_name))\n",
    "wav_anno_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee658d49-2009-450f-99bc-58e69a065454",
   "metadata": {},
   "source": [
    "**Note** for the annotation file 'raw/O5P5U-f00035_November_15_2022_07_26_50_Labels.txt', I deleted the last three annotations because they look abnormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce54bb4-6961-406a-a969-698c3cbf0f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_anno_list.sort( key = lambda x: -len(librosa.load( x[0], sr = 16000 )[0])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0f516e-6592-4dbc-814e-30b0fad5b3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_wav_anno_list = wav_anno_list[:2]\n",
    "test_wav_anno_list = wav_anno_list[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf56e8a-59af-42fa-9da4-39d103ddf784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_data_folder = \"data/dataset/Canary/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4db5c0-89e9-44dd-bf6b-9a992b00e151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(save_data_folder+\"train\")\n",
    "    os.makedirs(save_data_folder+\"test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625a11b5-c848-4b28-8426-a963a316a3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping between segments!\n",
      "overlapping between segments!\n"
     ]
    }
   ],
   "source": [
    "save_folder = save_data_folder+\"train/\"\n",
    "for wav_name, anno_name in train_wav_anno_list:\n",
    "    shutil.copy( wav_name, save_folder )\n",
    "    on_offset_list =[]\n",
    "    with open(anno_name,\"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                line_split = line.split(\"\\t\")\n",
    "                onset = float(line_split[0])\n",
    "                offset = float(line_split[1])\n",
    "                cluster = line_split[2].strip()\n",
    "                assert offset > onset\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "            try:\n",
    "                assert len(on_offset_list) == 0 or onset>=on_offset_list[-1][1]\n",
    "            except:\n",
    "                print(\"overlapping between segments!\")             \n",
    "                \n",
    "            on_offset_list.append((onset,offset,cluster))\n",
    "\n",
    "    onsets, offsets, clusters = list(zip(*on_offset_list))\n",
    "    dataframe = pd.DataFrame({\"onset\":onsets, \"offset\":offsets, \"cluster\":clusters })\n",
    "    dataframe.to_csv(save_folder + os.path.basename(wav_name)[:-4]+\".csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d05b7cc-0799-48ec-bf85-f58546d93134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_folder = save_data_folder + \"test/\"\n",
    "for wav_name, anno_name in test_wav_anno_list:\n",
    "    shutil.copy( wav_name, save_folder )\n",
    "    on_offset_list =[]\n",
    "    with open(anno_name,\"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                line_split = line.split(\"\\t\")\n",
    "                onset = float(line_split[0])\n",
    "                offset = float(line_split[1])\n",
    "                cluster = line_split[2].strip()\n",
    "                assert offset > onset\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "            try:\n",
    "                assert len(on_offset_list) == 0 or onset>=on_offset_list[-1][1]\n",
    "            except:\n",
    "                print(\"overlapping between segments!\")\n",
    "\n",
    "                \n",
    "            on_offset_list.append((onset,offset,cluster ))\n",
    "\n",
    "    onsets, offsets, clusters = list(zip(*on_offset_list))\n",
    "    dataframe = pd.DataFrame({\"onset\":onsets, \"offset\":offsets, \"cluster\":clusters })\n",
    "    dataframe.to_csv(save_folder + os.path.basename(wav_name)[:-4]+\".csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f75402-7813-4233-8da6-218d409786fd",
   "metadata": {},
   "source": [
    "# DAS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686ea83-b218-4f6b-a217-20cc17c49b93",
   "metadata": {},
   "source": [
    "## Zebra finch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3ba0c1-63c0-4990-b0e5-4f9cb6d69439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"data/raw/DAS/zebra_finch/\"\n",
    "csv_train_test = {}\n",
    "for line in open(folder + \"/traintestsplit.txt\"):\n",
    "    line_split = line.split()\n",
    "    csv_train_test[line_split[0]] = line_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11951702-bf11-4f5b-b80e-fe4f2c0d2ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_csv_file_list = [ ]\n",
    "for fname in os.listdir(folder):\n",
    "    if fname.endswith(\".wav\"):\n",
    "        wav_name = folder + \"/\" + fname\n",
    "        csv_name = wav_name[:-4]+\"_annotations.csv\"\n",
    "        \n",
    "        csv_basename = os.path.basename( csv_name )[:-4]\n",
    "        if not os.path.exists(csv_name) or csv_basename not in csv_train_test:\n",
    "            continue\n",
    "        if csv_train_test[csv_basename] == \"test\":\n",
    "            train_or_test = \"test\"\n",
    "        else:\n",
    "            train_or_test = \"train\"\n",
    "        \n",
    "        wav_csv_file_list.append( ( wav_name, csv_name, train_or_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bc6f14-b8d8-448f-9618-fc3384402a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"data/dataset/DAS/zebra_finch/train\")\n",
    "    os.makedirs(\"data/dataset/DAS/zebra_finch/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795c77b8-c70f-4f52-8aa2-bb2742164dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for wav_file_path, csv_file_path, train_or_test in wav_csv_file_list:\n",
    "    if train_or_test == \"train\":\n",
    "        save_path = \"data/dataset/DAS/zebra_finch/train/\"\n",
    "    else:\n",
    "        save_path = \"data/dataset/DAS/zebra_finch/test/\"\n",
    "    \n",
    "    wav_file_basename = os.path.basename( wav_file_path )\n",
    "    shutil.copy( wav_file_path, save_path + \"/\" + wav_file_basename )\n",
    "    \n",
    "    anno_data = pd.read_csv( csv_file_path )\n",
    "    \n",
    "    anno_structured = {}\n",
    "    anno_structured[ \"onset\" ] = anno_data[\"start_seconds\"]\n",
    "    anno_structured[ \"offset\" ] = anno_data[\"stop_seconds\"]\n",
    "    anno_structured[ \"cluster\" ] = anno_data[\"name\"]\n",
    "    anno_structured = pd.DataFrame( anno_structured )\n",
    "    assert np.all(anno_structured[ \"offset\" ] - anno_structured[ \"onset\" ] >0)\n",
    "    \n",
    "    csv_file_basename = wav_file_basename[:-4] + \".csv\"\n",
    "    anno_structured.to_csv( save_path + \"/\" + csv_file_basename, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0cbf9-ae5f-4dcd-b20b-94a426bae368",
   "metadata": {},
   "source": [
    "# Meerkat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc4eb80-ff48-48f5-a92a-7a476107739f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import librosa\n",
    "from glob import glob\n",
    "import os\n",
    "from io import StringIO\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892069d4-32e4-48d5-b707-1df72e663e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/raw/Meerkat/meerkat/ZIP040_SingleCallTypesMerged_2022_ML_03.wav',\n",
       "  'data/raw/Meerkat/meerkat/ZIP040_SingleCallTypesMerged_2022_ML_03.csv'),\n",
       " ('data/raw/Meerkat/meerkat/ZIP040_2022_ML_01.wav',\n",
       "  'data/raw/Meerkat/meerkat/ZIP040_2022_ML_01.csv'),\n",
       " ('data/raw/Meerkat/meerkat/ZIP040_2022_ML_02.wav',\n",
       "  'data/raw/Meerkat/meerkat/ZIP040_2022_ML_02.csv'),\n",
       " ('data/raw/Meerkat/meerkat/VALP009_AL_5_15DEC2022_MF_ML.WAV',\n",
       "  'data/raw/Meerkat/meerkat/VALP009_AL_5_15DEC2022_MF_ML.csv'),\n",
       " ('data/raw/Meerkat/meerkat/VLM298_L_4_27DEC2022_MF_ML.WAV',\n",
       "  'data/raw/Meerkat/meerkat/VLM298_L_4_27DEC2022_MF_ML.csv'),\n",
       " ('data/raw/Meerkat/meerkat/VALP007_AL_6_15DEC2022_MF_ML.WAV',\n",
       "  'data/raw/Meerkat/meerkat/VALP007_AL_6_15DEC2022_MF_ML.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file_list = glob(\"data/raw/Meerkat/meerkat/*.wav\") + glob(\"data/raw/Meerkat/meerkat/*.WAV\")\n",
    "csv_file_list = []\n",
    "for audio_file in audio_file_list:\n",
    "    if os.path.exists( audio_file[:-3] + \"csv\" ):\n",
    "        csv_file_list.append( audio_file[:-3] + \"csv\" )\n",
    "    else:\n",
    "        assert os.path.exists( audio_file[:-3] + \"CSV\" )\n",
    "        csv_file_list.append( audio_file[:-3] + \"CSV\" )\n",
    "assert len(audio_file_list) == len(csv_file_list) \n",
    "list(zip( audio_file_list, csv_file_list ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e558f20d-d5fa-4b26-b5b6-fc1f43433e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_audio_list = []\n",
    "for audio_file in audio_file_list:\n",
    "    audio, sr = librosa.load( audio_file, mono=False )\n",
    "    clean_audio_list.append(\n",
    "        {\n",
    "            \"audio\":audio[0],\n",
    "            \"sr\":sr\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bab20cc-797f-4b43-a85a-bc12e6f37302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anno_list = []\n",
    "for csv_file in csv_file_list:\n",
    "    lines = []\n",
    "    for line in open(csv_file,\"r\").readlines():\n",
    "        line = line.replace('\"','')\n",
    "        lines.append(line)\n",
    "    csv_data = \"\\n\".join( lines )\n",
    "    df = pd.read_csv(StringIO(csv_data), sep='\\t')\n",
    "    \n",
    "    anno_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7aca4c9-f126-43af-b47b-c0898e88b22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decimal_to_seconds( decimal_time ):\n",
    "    splits = decimal_time.split(\":\")\n",
    "    if len(splits) == 2:\n",
    "        hours = 0\n",
    "        minutes, seconds = splits\n",
    "    elif len(splits) == 3:\n",
    "        hours, minutes, seconds = splits\n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "    return int(hours) * 3600 + int(minutes) * 60 + float(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcd4d90-b922-4a28-b956-f88128ac8864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_anno_list = []\n",
    "for anno in anno_list:\n",
    "    onset_list = []\n",
    "    offset_list = []\n",
    "    cluster_list = []\n",
    "    for onset, duration in zip( anno[\"Start\"], anno[\"Duration\"] ):\n",
    "        onset_list.append( decimal_to_seconds( onset ) )\n",
    "        offset_list.append( decimal_to_seconds( onset ) + decimal_to_seconds( duration ) )\n",
    "        cluster_list.append( \"0\" )\n",
    "    \n",
    "    clean_anno_list.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"onset\":onset_list,\n",
    "                \"offset\":offset_list,\n",
    "                \"cluster\":cluster_list\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6912967a-9c91-40c8-89bf-e1dfaba92977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "\n",
    "for idx in range(len(clean_audio_list)):\n",
    "    audio = clean_audio_list[idx][\"audio\"]\n",
    "    sr = clean_audio_list[idx][\"sr\"]\n",
    "    anno = clean_anno_list[idx]\n",
    "    \n",
    "    fname = os.path.basename( audio_file_list[idx] )[:-4]\n",
    "    \n",
    "    ## use either the first 10% or the last 10% of the recording for testing\n",
    "    if np.random.choice(2) == 0:\n",
    "        ratio = 0.1\n",
    "    else:\n",
    "        ratio = 0.9\n",
    "        \n",
    "    split_point = int( len( audio ) * ratio )\n",
    "    split_time = split_point / sr\n",
    "    \n",
    "    audio1 = audio[:split_point]\n",
    "    audio2 = audio[split_point:]\n",
    "    \n",
    "    anno1 = anno[ anno[\"onset\"] < split_time ].copy()\n",
    "    anno1[\"offset\"] = np.minimum( anno1[\"offset\"], split_time )\n",
    "    \n",
    "    anno2 = anno[ anno[\"offset\"] > split_time ].copy()\n",
    "    anno2[\"onset\"] = np.maximum( anno2[\"onset\"] - split_time, 0.0 )\n",
    "    anno2[\"offset\"] = anno2[\"offset\"] - split_time\n",
    "    \n",
    "    \n",
    "    if ratio == 0.1:\n",
    "        train_audio = audio2\n",
    "        train_anno = anno2\n",
    "        test_audio = audio1\n",
    "        test_anno = anno1\n",
    "    else:\n",
    "        train_audio = audio1\n",
    "        train_anno = anno1\n",
    "        test_audio = audio2\n",
    "        test_anno = anno2\n",
    "        \n",
    "    train_corpus.append(\n",
    "            {\n",
    "                \"audio\":train_audio,\n",
    "                \"annotation\":train_anno,\n",
    "                \"sr\":sr,\n",
    "                \"name\":fname\n",
    "            }\n",
    "    )\n",
    "    test_corpus.append(\n",
    "            {\n",
    "                \"audio\":test_audio,\n",
    "                \"annotation\":test_anno,\n",
    "                \"sr\":sr,\n",
    "                \"name\":fname\n",
    "            }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0e7b20-1ff3-4d57-a700-b5b8651ec0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"data/dataset/meerkat/train\", exist_ok=True)\n",
    "os.makedirs(\"data/dataset/meerkat/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd63a8ca-db95-4fba-940a-74349cea10a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for example in train_corpus:\n",
    "    audio_name = \"data/dataset/meerkat/train/\" + example[\"name\"] + \".wav\"\n",
    "    csv_name = \"data/dataset/meerkat/train/\" + example[\"name\"] + \".csv\"\n",
    "    \n",
    "    sf.write(audio_name, example[\"audio\"], example[\"sr\"], 'PCM_24')\n",
    "    example[\"annotation\"].to_csv( csv_name, index = False )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caea36c9-4d02-442f-9f91-e5fd9dcd0128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for example in test_corpus:\n",
    "    audio_name = \"data/dataset/meerkat/test/\" + example[\"name\"] + \".wav\"\n",
    "    csv_name = \"data/dataset/meerkat/test/\" + example[\"name\"] + \".csv\"\n",
    "    \n",
    "    sf.write(audio_name, example[\"audio\"], example[\"sr\"], 'PCM_24')\n",
    "    example[\"annotation\"].to_csv( csv_name, index = False )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6ea1a-a57a-4cd7-b274-de9b344a35c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
