{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aaf7fb-ebaf-44e9-92e9-810d302bffcd",
   "metadata": {},
   "source": [
    "Note: This is a script for preparing the dataset. Runnning this script requires a animal call database.\n",
    "Therefore, this script is only for internal debugging purpose. You can create the training / test dataset using your own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d51632d-c982-42dc-9923-4683a75bbf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()) )\n",
    "from database_manager import WavDB\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adac36f2-dceb-4007-a1e6-6aa2c86aacc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_path = \"../../data/database/DB.splite\"\n",
    "archive_folder = \"../../data/database/archive/\"\n",
    "wav_db = WavDB( db_path = db_path, archive_folder = archive_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9b1518-83b0-437b-9836-f88147057863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122cffc-51e7-461d-b22b-bf5df538c147",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Zebseg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657dacf-3ad6-4c04-962e-58f5585c4005",
   "metadata": {},
   "source": [
    "## Separate bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4868c73-5375-4843-b2c0-f0e900623db6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 233.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 287.83it/s]\n",
      "100%|███████████████████████████████████████████████████████| 45/45 [00:00<00:00, 438.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 496.30it/s]\n",
      "100%|█████████████████████████████████████████████████████| 177/177 [00:00<00:00, 433.79it/s]\n",
      "100%|███████████████████████████████████████████████████████| 19/19 [00:00<00:00, 512.41it/s]\n",
      "100%|███████████████████████████████████████████████████████| 45/45 [00:00<00:00, 511.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 495.41it/s]\n",
      "100%|███████████████████████████████████████████████████████| 32/32 [00:00<00:00, 468.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 338.14it/s]\n",
      "100%|█████████████████████████████████████████████████████| 257/257 [00:00<00:00, 495.26it/s]\n",
      "100%|███████████████████████████████████████████████████████| 28/28 [00:00<00:00, 533.76it/s]\n",
      "100%|███████████████████████████████████████████████████████| 45/45 [00:00<00:00, 533.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 580.14it/s]\n",
      "100%|███████████████████████████████████████████████████████| 44/44 [00:00<00:00, 501.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 498.46it/s]\n",
      "100%|███████████████████████████████████████████████████████| 70/70 [00:00<00:00, 549.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 515.65it/s]\n",
      "100%|███████████████████████████████████████████████████████| 45/45 [00:00<00:00, 485.18it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 388.26it/s]\n",
      "100%|███████████████████████████████████████████████████████| 22/22 [00:00<00:00, 418.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 460.71it/s]\n",
      "100%|███████████████████████████████████████████████████████| 14/14 [00:00<00:00, 421.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 275.09it/s]\n",
      "100%|█████████████████████████████████████████████████████| 893/893 [00:01<00:00, 631.39it/s]\n",
      "100%|███████████████████████████████████████████████████████| 99/99 [00:00<00:00, 638.98it/s]\n",
      "100%|█████████████████████████████████████████████████████| 746/746 [00:01<00:00, 579.87it/s]\n",
      "100%|███████████████████████████████████████████████████████| 82/82 [00:00<00:00, 583.11it/s]\n",
      "100%|███████████████████████████████████████████████████████| 72/72 [00:00<00:00, 611.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 606.65it/s]\n",
      "100%|███████████████████████████████████████████████████████| 90/90 [00:00<00:00, 634.44it/s]\n",
      "100%|███████████████████████████████████████████████████████| 10/10 [00:00<00:00, 618.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for bird_and_age in [\"R3406_035\", \"R3406_045\", \"R3406_055\",\n",
    "                     \"R3428_039\", \"R3428_049\", \"R3428_059\",\n",
    "                     \"R3549_043\", \"R3549_053\", \"R3549_063\",\n",
    "                     \"R3625_045\", \"R3625_055\", \"R3625_065\",\n",
    "                     \"g17y2\", \"g4p5\", \"g19o10\", \"g19o3\"\n",
    "                    ]:\n",
    "    bird_name, bird_age = (bird_and_age.split(\"_\")+[\"\"])[:2]\n",
    "    \n",
    "    for mode in [\"train\", \"test\"]:\n",
    "    \n",
    "        dataset_folder = f\"data/dataset/zebseg/{bird_and_age}/{mode}\"\n",
    "        os.makedirs(dataset_folder)\n",
    "        audio_path_list, label_path_list = wav_db.get_audio_and_label_paths( \n",
    "             ( f\"collection=='zebseg' AND participant_name=='{bird_name}' AND participant_age=='{bird_age}' AND train_or_test=='{mode}'\", [] )  )    \n",
    "\n",
    "        for audio_path, csv_path in tqdm(zip(audio_path_list, label_path_list), total=len(audio_path_list)):\n",
    "            assert audio_path.endswith(\".wav\") and csv_path.endswith(\".csv\")\n",
    "            shutil.copy( audio_path, dataset_folder+\"/\" )\n",
    "            shutil.copy( csv_path, dataset_folder+\"/\" )\n",
    "            \n",
    "            csv_basename = os.path.basename( csv_path )\n",
    "            target_csv_path = dataset_folder + \"/\" + csv_basename\n",
    "            label_df = pd.read_csv( target_csv_path )\n",
    "            onset = np.array(label_df[\"onset\"])\n",
    "            duration = np.array(label_df[\"duration\"])\n",
    "            offset = onset + duration\n",
    "            cluster = np.array([0] * len(onset))\n",
    "            pd.DataFrame(\n",
    "                    {\"onset\":onset,\n",
    "                     \"offset\":offset,\n",
    "                     \"cluster\":cluster\n",
    "                    }\n",
    "            ).to_csv( target_csv_path, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0288df-5452-4d83-81fa-73b5597cd2c6",
   "metadata": {},
   "source": [
    "## All Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4808225-3a2f-4ecf-8e07-49f9e8df3885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 2606/2606 [00:06<00:00, 386.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"data/dataset/zebseg/all_birds/train\"\n",
    "os.makedirs(dataset_folder)\n",
    "audio_path_list, label_path_list = wav_db.get_audio_and_label_paths( \n",
    "     ( \"collection=='zebseg' AND train_or_test=='train'\", [] )  )\n",
    "\n",
    "for audio_path, csv_path in tqdm(zip(audio_path_list, label_path_list), total=len(audio_path_list)):\n",
    "    assert audio_path.endswith(\".wav\") and csv_path.endswith(\".csv\")\n",
    "    shutil.copy( audio_path, dataset_folder+\"/\" )\n",
    "    shutil.copy( csv_path, dataset_folder+\"/\" )\n",
    "    \n",
    "    csv_basename = os.path.basename( csv_path )\n",
    "    target_csv_path = dataset_folder + \"/\" + csv_basename\n",
    "    label_df = pd.read_csv( target_csv_path )\n",
    "    onset = np.array(label_df[\"onset\"])\n",
    "    duration = np.array(label_df[\"duration\"])\n",
    "    offset = onset + duration\n",
    "    cluster = np.array([0] * len(onset))\n",
    "    pd.DataFrame(\n",
    "            {\"onset\":onset,\n",
    "             \"offset\":offset,\n",
    "             \"cluster\":cluster\n",
    "            }\n",
    "    ).to_csv( target_csv_path, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8202ae6a-b830-4c52-b9da-3e2701029ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 283/283 [00:00<00:00, 393.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"data/dataset/zebseg/all_birds/test\"\n",
    "os.makedirs(dataset_folder)\n",
    "audio_path_list, label_path_list = wav_db.get_audio_and_label_paths( \n",
    "     ( \"collection=='zebseg' AND train_or_test=='test'\", [] )  )\n",
    "\n",
    "for audio_path, csv_path in tqdm(zip(audio_path_list, label_path_list), total=len(audio_path_list)):\n",
    "    assert audio_path.endswith(\".wav\") and csv_path.endswith(\".csv\")\n",
    "    shutil.copy( audio_path, dataset_folder+\"/\" )\n",
    "    shutil.copy( csv_path, dataset_folder+\"/\" )\n",
    "    \n",
    "    csv_basename = os.path.basename( csv_path )\n",
    "    target_csv_path = dataset_folder + \"/\" + csv_basename\n",
    "    label_df = pd.read_csv( target_csv_path )\n",
    "    onset = np.array(label_df[\"onset\"])\n",
    "    duration = np.array(label_df[\"duration\"])\n",
    "    offset = onset + duration\n",
    "    cluster = np.array([0] * len(onset))\n",
    "    pd.DataFrame(\n",
    "            {\"onset\":onset,\n",
    "             \"offset\":offset,\n",
    "             \"cluster\":cluster\n",
    "            }\n",
    "    ).to_csv( target_csv_path, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522679d-b4a9-4951-bcf7-b08180cb0271",
   "metadata": {},
   "source": [
    "# Canary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c9dcb0-d5a6-4567-b47c-820b876a6ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/raw/Canary/O5P5U-f00035_November_15_2022_07_26_50.wav',\n",
       "  'data/raw/Canary/O5P5U-f00035_November_15_2022_07_26_50_Labels.txt'),\n",
       " ('data/raw/Canary/O5P5U-f00010_November_15_2022_07_15_19.wav',\n",
       "  'data/raw/Canary/O5P5U-f00010_November_15_2022_07_15_19_Labels.txt'),\n",
       " ('data/raw/Canary/O5P5U-f00019_November_15_2022_07_21_37.wav',\n",
       "  'data/raw/Canary/O5P5U-f00019_November_15_2022_07_21_37_Labels.txt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_anno_list = []\n",
    "raw_data_folder = \"data/raw/Canary/\"\n",
    "for fname in os.listdir(raw_data_folder):\n",
    "    if fname.endswith(\".wav\"):\n",
    "        wav_name = raw_data_folder+fname\n",
    "        anno_name = wav_name[:-4] + \"_Labels.txt\"\n",
    "        if os.path.exists(anno_name):\n",
    "            wav_anno_list.append((wav_name, anno_name))\n",
    "wav_anno_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee658d49-2009-450f-99bc-58e69a065454",
   "metadata": {},
   "source": [
    "**Note** for the annotation file 'raw/O5P5U-f00035_November_15_2022_07_26_50_Labels.txt', I deleted the last three annotations because they look abnormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce54bb4-6961-406a-a969-698c3cbf0f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_anno_list.sort( key = lambda x: -len(librosa.load( x[0], sr = 16000 )[0])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0f516e-6592-4dbc-814e-30b0fad5b3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_wav_anno_list = wav_anno_list[:2]\n",
    "test_wav_anno_list = wav_anno_list[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf56e8a-59af-42fa-9da4-39d103ddf784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_data_folder = \"data/dataset/Canary/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4db5c0-89e9-44dd-bf6b-9a992b00e151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(save_data_folder+\"train\")\n",
    "    os.makedirs(save_data_folder+\"test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625a11b5-c848-4b28-8426-a963a316a3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping between segments!\n",
      "overlapping between segments!\n"
     ]
    }
   ],
   "source": [
    "save_folder = save_data_folder+\"train/\"\n",
    "for wav_name, anno_name in train_wav_anno_list:\n",
    "    shutil.copy( wav_name, save_folder )\n",
    "    on_offset_list =[]\n",
    "    with open(anno_name,\"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                line_split = line.split(\"\\t\")\n",
    "                onset = float(line_split[0])\n",
    "                offset = float(line_split[1])\n",
    "                cluster = line_split[2].strip()\n",
    "                assert offset > onset\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "            try:\n",
    "                assert len(on_offset_list) == 0 or onset>=on_offset_list[-1][1]\n",
    "            except:\n",
    "                print(\"overlapping between segments!\")             \n",
    "                \n",
    "            on_offset_list.append((onset,offset,cluster))\n",
    "\n",
    "    onsets, offsets, clusters = list(zip(*on_offset_list))\n",
    "    dataframe = pd.DataFrame({\"onset\":onsets, \"offset\":offsets, \"cluster\":clusters })\n",
    "    dataframe.to_csv(save_folder + os.path.basename(wav_name)[:-4]+\".csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d05b7cc-0799-48ec-bf85-f58546d93134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_folder = save_data_folder + \"test/\"\n",
    "for wav_name, anno_name in test_wav_anno_list:\n",
    "    shutil.copy( wav_name, save_folder )\n",
    "    on_offset_list =[]\n",
    "    with open(anno_name,\"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                line_split = line.split(\"\\t\")\n",
    "                onset = float(line_split[0])\n",
    "                offset = float(line_split[1])\n",
    "                cluster = line_split[2].strip()\n",
    "                assert offset > onset\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "            try:\n",
    "                assert len(on_offset_list) == 0 or onset>=on_offset_list[-1][1]\n",
    "            except:\n",
    "                print(\"overlapping between segments!\")\n",
    "\n",
    "                \n",
    "            on_offset_list.append((onset,offset,cluster ))\n",
    "\n",
    "    onsets, offsets, clusters = list(zip(*on_offset_list))\n",
    "    dataframe = pd.DataFrame({\"onset\":onsets, \"offset\":offsets, \"cluster\":clusters })\n",
    "    dataframe.to_csv(save_folder + os.path.basename(wav_name)[:-4]+\".csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f75402-7813-4233-8da6-218d409786fd",
   "metadata": {},
   "source": [
    "# DAS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686ea83-b218-4f6b-a217-20cc17c49b93",
   "metadata": {},
   "source": [
    "## Zebra finch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3ba0c1-63c0-4990-b0e5-4f9cb6d69439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"data/raw/DAS/zebra_finch/\"\n",
    "csv_train_test = {}\n",
    "for line in open(folder + \"/traintestsplit.txt\"):\n",
    "    line_split = line.split()\n",
    "    csv_train_test[line_split[0]] = line_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11951702-bf11-4f5b-b80e-fe4f2c0d2ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_csv_file_list = [ ]\n",
    "for fname in os.listdir(folder):\n",
    "    if fname.endswith(\".wav\"):\n",
    "        wav_name = folder + \"/\" + fname\n",
    "        csv_name = wav_name[:-4]+\"_annotations.csv\"\n",
    "        \n",
    "        csv_basename = os.path.basename( csv_name )[:-4]\n",
    "        if not os.path.exists(csv_name) or csv_basename not in csv_train_test:\n",
    "            continue\n",
    "        if csv_train_test[csv_basename] == \"test\":\n",
    "            train_or_test = \"test\"\n",
    "        else:\n",
    "            train_or_test = \"train\"\n",
    "        \n",
    "        wav_csv_file_list.append( ( wav_name, csv_name, train_or_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bc6f14-b8d8-448f-9618-fc3384402a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"data/dataset/DAS/zebra_finch/train\")\n",
    "    os.makedirs(\"data/dataset/DAS/zebra_finch/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795c77b8-c70f-4f52-8aa2-bb2742164dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for wav_file_path, csv_file_path, train_or_test in wav_csv_file_list:\n",
    "    if train_or_test == \"train\":\n",
    "        save_path = \"data/dataset/DAS/zebra_finch/train/\"\n",
    "    else:\n",
    "        save_path = \"data/dataset/DAS/zebra_finch/test/\"\n",
    "    \n",
    "    wav_file_basename = os.path.basename( wav_file_path )\n",
    "    shutil.copy( wav_file_path, save_path + \"/\" + wav_file_basename )\n",
    "    \n",
    "    anno_data = pd.read_csv( csv_file_path )\n",
    "    \n",
    "    anno_structured = {}\n",
    "    anno_structured[ \"onset\" ] = anno_data[\"start_seconds\"]\n",
    "    anno_structured[ \"offset\" ] = anno_data[\"stop_seconds\"]\n",
    "    anno_structured[ \"cluster\" ] = anno_data[\"name\"]\n",
    "    anno_structured = pd.DataFrame( anno_structured )\n",
    "    assert np.all(anno_structured[ \"offset\" ] - anno_structured[ \"onset\" ] >0)\n",
    "    \n",
    "    csv_file_basename = wav_file_basename[:-4] + \".csv\"\n",
    "    anno_structured.to_csv( save_path + \"/\" + csv_file_basename, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f5ac3-58c0-4c15-91c4-412ddd34d3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
